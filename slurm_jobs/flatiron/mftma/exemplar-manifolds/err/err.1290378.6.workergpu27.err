Traceback (most recent call last):
  File "exemplar_analysis_parallel.py", line 224, in <module>
    features_dict = extract_representations(model_name, model, norm_method, X_adv)
  File "exemplar_analysis_parallel.py", line 124, in extract_representations
    Y_hat = model(torch.tensor(X_adv))
  File "/mnt/home/blyo1/ceph/envs/pyenv36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "../mnist_layer_norm.py", line 67, in forward
    x = self.conv_1(x)
  File "/mnt/home/blyo1/ceph/envs/pyenv36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/mnt/home/blyo1/ceph/envs/pyenv36/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 423, in forward
    return self._conv_forward(input, self.weight)
  File "/mnt/home/blyo1/ceph/envs/pyenv36/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 420, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same
